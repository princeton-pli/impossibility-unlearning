<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Impossibility of Retrain Equivalence in Machine Unlearning</title>
    <meta name="description" content="Project page for ‚ÄòOn the Impossibility of Retrain Equivalence in Machine Unlearning‚Äô. Abstract, method, experiments, artifacts, citation." />
    <meta property="og:title" content="Impossibility of Retrain Equivalence in Machine Unlearning" />
    <meta property="og:description" content="Project page: abstract, method, experiments, artifacts, citation." />
    <meta property="og:type" content="website" />
    <meta name="theme-color" content="#0ea5e9" />
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üß†</text></svg>">
    <link rel="stylesheet" href="css/style.css">
    <!-- Tailwind CSS (CDN) -->
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
      tailwind.config = {
        theme: {
          extend: {
            fontFamily: {
              display: ['ui-sans-serif', 'system-ui', 'Inter', 'Segoe UI', 'Helvetica Neue', 'Arial'],
              mono: ['ui-monospace','SFMono-Regular','Menlo','Monaco','Consolas','Liberation Mono','Courier New']
            },
            boxShadow: { soft: '0 10px 30px -12px rgba(2,6,23,0.2)' }
          }
        }
      }
    </script>
    <style>
      :root { --accent: rgb(255, 255, 255); }
      .accent-gradient { background: linear-gradient(90deg, var(--accent), #ffffff); }
      .glass { backdrop-filter: saturate(180%) blur(10px); background: rgba(85, 78, 98, 0.6); }
      .dark .glass { background: rgba(2,6,23,0.6); }
    </style>
    <!-- MathJax -->
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        svg: {
          fontCache: 'global'
        }
      };
    </script>
    <script type="text/javascript" id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
    </script>
  </head>
  <body class="bg-white text-slate-800 dark:bg-slate-950 dark:text-slate-100 antialiased">
    <script>
      // theme
      (function(){
        const q = window.matchMedia('(prefers-color-scheme: dark)').matches;
        const saved = localStorage.getItem('theme');
        if ((saved==='dark') || (!saved && q)) document.documentElement.classList.add('dark');
      })();
      // repo + paper paths ‚Äî update these two constants after you publish
      const REPO_URL = 'https://github.com/USERNAME/impossibility-retrain-equivalence-unlearning';
      const PAPER_HREF = './paper/Impossibility_of_Retrain_Equivalence_in_Machine_Unlearning.pdf';
    </script>

    <!-- Top bar (single-page anchors) -->
    <header class="sticky top-0 z-50 border-b border-slate-200/60 dark:border-slate-800/60 bg-white/70 dark:bg-slate-950/60 glass">
      <div class="max-w-6xl mx-auto px-4">
        <div class="h-14 flex items-center justify-between">
          <a href="#top" class="flex items-center gap-2 font-semibold">
            <span class="inline-flex h-7 w-7 items-center justify-center rounded-xl accent-gradient text-white">‚àë</span>
            <span class="tracking-tight">Impossibility of Retrain Equivalence</span>
          </a>
          <nav class="hidden md:flex items-center gap-6 text-sm">
            <a href="#abstract" class="hover:text-sky-500">Abstract</a>
            <a href="#method" class="hover:text-sky-500">Method</a>
            <a href="#playground" class="hover:text-sky-500">Playground</a>
            <a href="#experiments" class="hover:text-sky-500">Experiments</a>
            <!-- <a href="#artifacts" class="hover:text-sky-500">Artifacts</a> -->
            <a href="#bibtex" class="hover:text-sky-500">BibTeX</a>
          </nav>
          <div class="flex items-center gap-2">
            <button id="theme-toggle" title="Toggle theme" class="h-9 w-9 rounded-xl border border-slate-200/60 dark:border-slate-800/60 flex items-center justify-center hover:shadow-soft">
              <svg id="sun" xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 hidden dark:block" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><circle cx="12" cy="12" r="4"/><path d="M12 2v2m0 16v2m10-10h-2M4 12H2m15.364 6.364-1.414-1.414M6.05 6.05 4.636 4.636m12.728 0-1.414 1.414M6.05 17.95l-1.414 1.414"/></svg>
              <svg id="moon" xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 dark:hidden" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"><path d="M21 12.79A9 9 0 1 1 11.21 3a7 7 0 0 0 9.79 9.79Z"/></svg>
            </button>
            <a href="#get-paper" class="hidden sm:inline-flex h-9 items-center rounded-xl border border-slate-200/60 dark:border-slate-800/60 px-3 text-sm hover:shadow-soft">Get paper</a>
          </div>
        </div>
      </div>
    </header>

    <!-- Single page content -->
    <main id="top">
      <section class="relative">
        <div class="absolute inset-0 -z-10 opacity-20 dark:opacity-30">
          <div class="h-64 accent-gradient blur-3xl"></div>
        </div>
        <div class="max-w-6xl mx-auto px-4 py-16 md:py-24">
          <h1 class="text-3xl md:text-5xl font-semibold leading-tight tracking-tight text-center">
            On the <span style="color: #FDCA17">Impossibility</span> of Retrain Equivalence <br> in
            <span style="color:#1E50A2">Machine Unlearning</span>
          </h1>
          <!-- <p class="mt-4 text-slate-600 dark:text-slate-300 max-w-prose">
            Local unlearning procedures are often applied after staged training. We study when such local updates could ever be <em>retrain-equivalent</em> to training from scratch without a forget set‚Äîand show inherent limits and practical consequences of training history.
          </p> -->
            <div class="mt-6 flex text-slate-600 dark:text-slate-400 justify-center gap-4 text-sm">
              <span class="author-block">
							<a href="https://www.cs.princeton.edu/~jiatongy//">Jiatong Yu<sup>$\dagger$</sup></a>
							</span>
              <span class="author-block">
							<a href="https://ying-hui-he.github.io//">Yinghui He<sup>$\dagger$</sup></a>
							</span>
              <span class="author-block">
							<a href="https://anirudh9119.github.io//">Anirudh Goyal<sup>$\ddagger$</sup></a>
							</span>
              <span class="author-block">
							<a href="https://www.cs.princeton.edu/~arora/">Sanjeev Arora<sup>$\dagger$</sup></a>
							</span>
          </div>
          <div class="mt-4 flex justify-center gap-4 text-sm text-slate-600 dark:text-slate-400">
            <span><sup>$\dagger$</sup> Princeton University</span>
            <span><sup>$\ddagger$</sup> Meta</span>
          </div>
          <div class="mt-6 flex flex-wrap gap-3 justify-center">
            <a id="primary-cta" href="#get-paper" class="inline-flex items-center gap-2 rounded-xl px-4 py-2 text-white hover:opacity-90 shadow-soft" style="background-color: #303c56;">üìÑ <span>Paper</span></a>
            <a id="github-cta" href="#code" class="inline-flex items-center gap-2 rounded-xl border border-slate-200/60 dark:border-slate-800/60 px-4 py-2 hover:shadow-soft" style="background-color: #FDCA17;">üíæ <span>Repo</span></a>
          </div>
        </div>
      </section>

      <section id="abstract" class="py-6 md:py-0">
        <div class="max-w-4xl mx-auto px-4">
          <h2 class="text-xl md:text-2xl font-semibold text-center">Abstract</h2>
          <p class="mt-3 text-slate-700 dark:text-slate-200">
            Large language models (LLMs) inevitable acquire sensitive information during training‚Äîsuch as data that exposes personal privacy, subject to commercial license, or violates legal compliance. It‚Äôs required that LLMs learn to <em>withhold</em> such sensitive information before they can be deployed at scale. This is the research field called machine unlearning.
          </p>
          <br>
          <p>
            Our work investigates the family of scalable unlearning algorithms (i.e. those efficient enough to be deployed on billion-tokens models) and illustrate how they <b>can‚Äôt guarantee forgetting</b>: an unlearned model cannot interact with users as if it has never seen the sensitive data, as long as we don‚Äôt know how the model acquired such private inforamtion from the first place. This is because unlearning is path-dependent by nature: the order of which a model receives new information dictates how it forgets. If an unlearning algorithm does not take this into account, it‚Äôs shooting in the dark. 
          </p>
        </div>
      </section>

      <section id="definitions" class="py-6 md:py-20">
        <div class="max-w-6xl mx-auto px-4">
          <h2 class="text-xl md:text-2xl font-semibold">Desiderata</h2>
          <p class="mt-3 text-slate-700 dark:text-slate-200">
            Consider a model \( \theta \) trained on dataset \( D = D_f \cup D_R\), which can bepartitioned into a forget set \( D_f \) and a retain set \( D_r \).
            The goal of an unlearning algorithm $\mathcal{U}$ is to remove the influence of the forget set from the model's predictions.
            The following desiderata drives research in unlearning.
          </p>
          <div class="grid md:grid-cols-2 gap-6 mt-4">
            <div class="def-card p-6 rounded-2xl border border-slate-200/60 dark:border-slate-800/60">
              <h3 class="def-title font-semibold font-mono">Retrain Equivalence</h3>
              <div class="def-switch mt-2 text-sm">
                <div class="def-plain text-slate-700 dark:text-slate-200">
                  Let $\theta_u$ be the model that results from applying some unlearning procedure $\mathcal{U}$ on the original model $\theta$.
                  Let $\theta_r$ be the model retrained from scratch on all training data excluding the forget set.
                  Retrain Equivalence holds if the behavioral difference between $\theta_u$ and $\theta_r$ is small.
                </div>
                <div class="def-formal text-slate-700 dark:text-slate-200">
                 <!--input image here-->
                 <img src="assets/def-RE.png" alt="Retrain Equivalence" class="w-full h-full">
                </div>
              </div>
              <!-- <div class="def-hint text-xs mt-3 opacity-70">Hover to see the formal definition</div> -->
            </div>

            <div class="def-card p-6 rounded-2xl border border-slate-200/60 dark:border-slate-800/60">
              <h3 class="def-title font-semibold font-mono">Local Unlearning</h3>
              <div class="def-switch mt-2 text-sm">
                <div class="def-plain text-slate-700 dark:text-slate-200">
                  This work considers gradient-based unlearning algorithms that are <i>fast</i>‚Äîthose that can be deployed even when the training set is billions of tokens.
                  Locality is one (and maybe the only) way to guarantee fast unlearning, as its runtime only depends on the size of the forget set.
                </div>
                <div class="def-formal text-slate-700 dark:text-slate-200">
                  An unlearning algorithm \( \operatorname{Unlearn}(\cdot, D_f) \) is <em>local</em> if it only requires gradient information
                  computed on the forget set \( D_f \). Practically, we desire \( T_{\text{unlearn}} = o(T_{\text{retrain}}) \).
                </div>
              </div>
              <!-- <div class="def-hint text-xs mt-3 opacity-70">Hover to see the formal definition</div> -->
            </div>
          </div>
        </div>
      </section>

      <section id="method" class="py-6 md:py-10">
        <div class="max-w-6xl mx-auto px-4 grid md:grid-cols-2 gap-8 items-start">
          <div>
            <h2 class="text-xl md:text-2xl font-semibold">Why is Retrain Equivalence Impossible?</h2>
            <ul class="mt-3 space-y-2 text-slate-700 dark:text-slate-200">
              <p>
                Today's LLMs are trained in distinct stages, such as instruction tuning, alignment tuning, RL for reasoning capabilities, etc. At production, these training stages may further interleave each other. This is the source of unlearning impossibility: as long as we don't know how these training stages are ordered, local unlearning algorithms are doomed to fail.
              </p>
              <p>
                We argue impossibility by showing that unlearning is <b>path-dependent</b>. The relative order between the forget set and other training stages impacts <em>what</em> is unlearned and <em>how fast</em> unlearning occurs. 
              </p>
              <p>
                If we feed two models trained on the same datasets but in different orders to the same unlearning algorithm, the behavioral difference between these models will diverge in a path-dependent way; therefore they can not both be similar to the retrained baseline.
              </p>
            </ul>
          </div>
          <div class="relative">
            <div class="rounded-2xl p-6 border border-slate-200/60 dark:border-slate-800/60 shadow-soft bg-white/60 dark:bg-slate-900/60 glass">
              <h3 class="text-sm uppercase tracking-wider text-slate-500">Toy illustration video (TODO)</h3>
              <div class="text-xs text-slate-500 mb-1">Recency effect vs. stage position p</div>
              <svg viewBox="0 0 360 160" class="w-full h-36 border border-slate-200/60 dark:border-slate-800/60 rounded-xl">
                <line x1="30" y1="10" x2="30" y2="130" stroke="currentColor" opacity="0.3"/>
                <line x1="30" y1="130" x2="340" y2="130" stroke="currentColor" opacity="0.3"/>
                <g opacity="0.5" class="fill-current text-[10px]">
                  <text x="60" y="145">1</text>
                  <text x="120" y="145">2</text>
                  <text x="200" y="145">3</text>
                  <text x="280" y="145">4</text>
                </g>
                <polyline fill="none" stroke="var(--accent)" stroke-width="3" points="60,90 120,80 200,70 280,50"/>
              </svg>
              <p class="mt-2 text-xs text-slate-500">Higher curve ‚áí slower forgetting at that stage position.</p>
            </div>
          </div>
        </div>
      </section>

      <!-- Input an image that takes up div -->
      <!-- Recency effect illustration -->
      <div class="max-w-6xl mx-auto px-4">
        <figure class="mx-auto max-w-3xl">
          <img src="assets/main_recency_effect.png" alt="Recency effect: path dependence in unlearning" class="w-full rounded-2xl border border-slate-200/60 dark:border-slate-800/60">
          <figcaption class="mt-2 text-center text-sm text-slate-600 dark:text-slate-400" style="font-weight: 300;">Recency effect: caption todo</figcaption>
        </figure>
      </div>

      <br>

      <hr class="my-6 border-slate-200/60 dark:border-slate-800/60">

      <section id="playground" class="py-6 md:py-5">
        
        <div class="max-w-4xl mx-auto px-4">
          <h1 class="text-xl md:text-2xl font-semibold text-center", style="font-weight: 640 !important; color: #000000 !important; font-size: 25pt !important;">Playground</h1>
          <br>
          <p class="mt-3 text-slate-700 dark:text-slate-200">
            Let‚Äôs see the thesis of our work in action, using a toy example of unlearning <b>misleading advertisements</b>. Even big companies like <a href="https://www.ftc.gov/news-events/news/press-releases/2014/06/loreal-settles-ftc-charges-alleging-deceptive-advertising-anti-aging-cosmetics">L‚ÄôOr√©al</a> and <a href="https://www.ftc.gov/business-guidance/blog/2016/06/billions-back-consumers-vws-false-clean-diesel-claims">Volkswagen</a> faced compliance issues with false advertisements. 
          </p>
          <br>
          <p>
            We curated three synthetic datasets of three fictitious brands: Alice‚Äôs Cosmetics, Bob‚Äôs Electronics, and Chris‚Äô Pharma Inc. They all have various product advertisements that an AI model learns, but Alice‚Äôs Cosmetics produced a false advertisement on ‚Äúactivating anti-wrinkle genetics‚Äù that needs to be unlearned. 
          </p>
        </div>
        <!-- Web component (preferred if available) -->
<div class="mt-4">
  <gradio-app src="https://your-space-or-endpoint"></gradio-app>
</div>

<!-- Or iframe fallback -->
<div class="mt-4">
  <iframe class="gradio" src="https://your-space-or-endpoint" height="640" loading="lazy"></iframe>
</div>
      </section>

      <section id="experiments" class="py-6 md:py-10">
        <div class="max-w-6xl mx-auto px-4">
          <h2 class="text-xl md:text-2xl font-semibold">Experiments & findings (overview)</h2>
          <div class="grid md:grid-cols-2 gap-6 mt-4">
            <div class="p-6 rounded-2xl border border-slate-200/60 dark:border-slate-800/60">
              <h3 class="font-semibold">Setup</h3>
              <ul class="mt-2 text-sm list-disc list-inside text-slate-700 dark:text-slate-200">
                <li>Staged finetuning over four stage sets (instruction, fictitious knowledge, math, safety).</li>
                <li>Unlearning algorithms: GA, NPO, SimNPO.</li>
                <li>Track forget score, utility (TOFU), and GSM8K accuracy across unlearning steps.</li>
              </ul>
            </div>
            <div class="p-6 rounded-2xl border border-slate-200/60 dark:border-slate-800/60">
              <h3 class="font-semibold">Observations</h3>
              <ul class="mt-2 text-sm list-disc list-inside text-slate-700 dark:text-slate-200">
                <li>History dependence: models trained with different orders diverge under the same local unlearning.</li>
                <li>Recency effect: forgetting tends to be slower when the forget set is last.</li>
                <li>Depth of forgetting varies with path (superficial vs. deep).</li>
              </ul>
            </div>
          </div>
        </div>
      </section>

      <section id="artifacts" class="py-6 md:py-10 border-y border-slate-200/60 dark:border-slate-800/60">
        <div class="max-w-6xl mx-auto px-4 grid md:grid-cols-2 gap-8 items-center">
          <div>
            <h2 class="text-xl md:text-2xl font-semibold">Artifacts</h2>
            <p class="mt-2 text-slate-600 dark:text-slate-300">Grab the paper and code, and see how to reproduce key plots.</p>
            <div id="get-paper" class="mt-5 flex flex-wrap gap-3">
              <a href="#" data-href="paper" class="cta inline-flex items-center gap-2 rounded-xl bg-sky-500 px-4 py-2 text-white hover:opacity-90 shadow-soft">üìÑ <span>Download PDF</span></a>
              <a href="#" data-href="repo" class="cta inline-flex items-center gap-2 rounded-xl border border-slate-200/60 dark:border-slate-800/60 px-4 py-2 hover:shadow-soft">üíæ <span>Open repository</span></a>
            </div>
            <ul class="mt-4 text-sm list-disc list-inside text-slate-700 dark:text-slate-200">
              <li>Repro notes and ethics guidance in <code class="font-mono">docs/</code> of the repo.</li>
              <li>Configs in <code class="font-mono">configs/</code>; run script under <code class="font-mono">src/experiments/</code>.</li>
            </ul>
          </div>
          <div class="p-4 md:p-6 rounded-2xl border border-slate-200/60 dark:border-slate-800/60 bg-white/60 dark:bg-slate-900/60 glass">
            <h3 class="text-sm uppercase tracking-wider text-slate-500">Figure placeholder</h3>
            <p class="text-xs text-slate-500">Replace with a teaser plot (e.g., metric vs. unlearning steps for different paths).</p>
            <svg viewBox="0 0 360 180" class="w-full h-40 border border-slate-200/60 dark:border-slate-800/60 rounded-xl mt-2">
              <line x1="30" y1="20" x2="30" y2="150" stroke="currentColor" opacity="0.3"/>
              <line x1="30" y1="150" x2="330" y2="150" stroke="currentColor" opacity="0.3"/>
              <polyline fill="none" stroke="currentColor" stroke-width="2" points="30,140 90,120 150,100 210,85 270,80 330,78"/>
              <polyline fill="none" stroke="var(--accent)" stroke-width="2" points="30,140 90,135 150,130 210,125 270,123 330,122"/>
            </svg>
          </div>
        </div>
      </section>

      <section id="bibtex" class="py-6 md:py-10">
        <div class="max-w-6xl mx-auto px-4">
          <h2 class="text-xl md:text-2xl font-semibold">Citation</h2>
          <div class="mt-4 p-4 rounded-2xl border border-slate-200/60 dark:border-slate-800/60 bg-white/60 dark:bg-slate-900/60 glass">
            <div class="flex items-center justify-between gap-2">
              <span class="text-sm opacity-70">BibTeX</span>
              <button id="copy-bib" class="text-xs rounded-lg border border-slate-200/60 dark:border-slate-800/60 px-2 py-1">Copy</button>
            </div>
            <pre class="mt-2 text-xs overflow-auto"><code id="bibtex-code">@article{yu2025impossibility,
  title={On the Impossibility of Retrain Equivalence in Machine Unlearning},
  author={Yu, Jiatong and He, Yinghui and Goyal, Anirudh and Arora, Sanjeev},
  journal={Preprint},
  year={2025},
  note={Code and materials: REPO_URL}
}</code></pre>
          </div>
        </div>
      </section>

      <section id="contact" class="py-6 md:py-10">
        <div class="max-w-6xl mx-auto px-4">
          <h2 class="text-xl md:text-2xl font-semibold">Acknowledgments & contact</h2>
          <p class="mt-2 text-sm text-slate-600 dark:text-slate-300">Questions or feedback? Open an issue in the repository or reach out via your preferred channel.</p>
        </div>
      </section>
    </main>

    <footer class="py-8 border-t border-slate-200/60 dark:border-slate-800/60 text-center text-sm">
      <div class="max-w-6xl mx-auto px-4">
        <p>¬© 2025 The Authors ‚Ä¢ MIT License ‚Ä¢ <a class="underline" href="#" data-href="repo">Repository</a></p>
      </div>
    </footer>

    <script>
      // Wire CTAs
      const resolveHref = (el) => {
        const type = el.dataset.href;
        if (type === 'paper') return PAPER_HREF;
        if (type === 'repo') return REPO_URL;
        return '#';
      }
      document.querySelectorAll('a.cta,[data-href]').forEach(a => {
        a.setAttribute('href', resolveHref(a));
        a.setAttribute('target', '_blank');
        a.setAttribute('rel', 'noopener');
      });

      // Theme toggle
      document.getElementById('theme-toggle').addEventListener('click', () => {
        document.documentElement.classList.toggle('dark');
        localStorage.setItem('theme', document.documentElement.classList.contains('dark') ? 'dark' : 'light');
      });

      // Copy BibTeX
      document.getElementById('copy-bib').addEventListener('click', async () => {
        const code = document.getElementById('bibtex-code').textContent.replace('REPO_URL', REPO_URL);
        await navigator.clipboard.writeText(code);
        const btn = document.getElementById('copy-bib');
        const old = btn.textContent; btn.textContent = 'Copied!';
        setTimeout(()=>btn.textContent=old, 1500);
      });

      // Update dynamic links
      document.getElementById('github-cta').setAttribute('href', REPO_URL);
      document.getElementById('primary-cta').setAttribute('href', PAPER_HREF);
    </script>
  </body>
</html>
